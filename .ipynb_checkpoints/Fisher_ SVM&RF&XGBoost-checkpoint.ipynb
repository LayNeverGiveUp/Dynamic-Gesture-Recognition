{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "from numpy import linalg as la\n",
    "from numpy.linalg import norm\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "import pdb\n",
    "from hmmlearn import hmm\n",
    "from sklearn.externals import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "path='/Users/lay/Desktop/DHG2016/'\n",
    "import shutil \n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gesture_list=['1','3','4'ï¼Œ'5','6']\n",
    "subject_list=[str(i) for i in range(1,21)]\n",
    "position_list=[str(i) for i in range(1,6)]\n",
    "path='/Users/lay/Desktop/DHG2016/'\n",
    "length=[1,0.5]\n",
    "num_joints=22\n",
    "wrist_index=[1]\n",
    "palm_index=[2]\n",
    "base_index=[3,7,11,15,19]\n",
    "first_index=[4,8,12,16,20]\n",
    "second_index=[5,9,13,17,21]\n",
    "tip_index=[6,10,14,18,22]\n",
    "tup={}\n",
    "tup['tup1']=[3,4,5,6]\n",
    "tup['tup2']=[7,8,9,10]\n",
    "tup['tup3']=[11,12,13,14]\n",
    "tup['tup4']=[15,16,17,18]\n",
    "tup['tup5']=[19,20,21,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handsize_normalization(start,end,length):\n",
    "    x=start\n",
    "    y=end\n",
    "    d=np.linalg.norm(y-x)\n",
    "    lamda=length/d\n",
    "    return lamda*(y-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rigid_transform_3D(A):\n",
    "    import numpy as np\n",
    "    A=np.mat(A)\n",
    "    B=np.mat([[0,-1,0],[0,0,0],[1,0,0]])\n",
    "    assert len(A) == len(B)\n",
    "    N = A.shape[0]\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    # centre the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "    # dot is matrix multiplication for array\n",
    "    H = np.transpose(AA) * BB\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T * U.T\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "       #print (\"Reflection detected\")\n",
    "        Vt[2,:] *= -1\n",
    "        R= Vt.T * U.T\n",
    "    t = -R*centroid_A.T + centroid_B.T\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer(R,t,nl):\n",
    "    import numpy as np\n",
    "    for i in range(4,23):\n",
    "        v=nl[(i-1)*3:i*3]\n",
    "        v=np.mat(v)\n",
    "        m=R*v.T + np.tile(t, (1, 1))\n",
    "        nl[(i-1)*3:i*3]=np.array(m.T)\n",
    "    return nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisher_vector(xx, gmm):\n",
    "    '''\n",
    "    Computes the Fisher vector on a set of descriptors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    xx: array_like, shape (N, D) or (D, )\n",
    "        The set of descriptors\n",
    "    gmm: instance of sklearn mixture.GMM object\n",
    "        Gauassian mixture model of the descriptors.\n",
    "    Returns\n",
    "    -------\n",
    "    fv: array_like, shape (K + 2 * D * K, )\n",
    "        Fisher vector (derivatives with respect to the mixing weights, means\n",
    "        and variances) of the given descriptors.\n",
    "    Reference\n",
    "    ---------\n",
    "    J. Krapac, J. Verbeek, F. Jurie.  Modeling Spatial Layout with Fisher\n",
    "    Vectors for Image Categorization.  In ICCV, 2011.\n",
    "    http://hal.inria.fr/docs/00/61/94/03/PDF/final.r1.pdf\n",
    "    '''\n",
    "    xx = np.atleast_2d(xx)\n",
    "    N = xx.shape[0]\n",
    "\n",
    "    # Compute posterior probabilities.\n",
    "    Q = gmm.predict_proba(xx)  # NxK\n",
    "\n",
    "    # Compute the sufficient statistics of descriptors.\n",
    "    Q_sum = np.sum(Q, 0)[:, np.newaxis] / N\n",
    "    Q_xx = np.dot(Q.T, xx) / N\n",
    "    Q_xx_2 = np.dot(Q.T, xx ** 2) / N\n",
    "\n",
    "    # Compute derivatives with respect to mixing weights, means and variances.\n",
    "    d_pi = Q_sum.squeeze() - gmm.weights_\n",
    "    d_mu = Q_xx - Q_sum * gmm.means_\n",
    "    d_sigma = (\n",
    "        - Q_xx_2\n",
    "        - Q_sum * gmm.means_ ** 2\n",
    "        + Q_sum * gmm.covars_\n",
    "        + 2 * Q_xx * gmm.means_)\n",
    "\n",
    "    # Merge derivatives into a vector.\n",
    "    return np.hstack((d_pi, d_mu.flatten(), d_sigma.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data generation\n",
    "X=[]\n",
    "Y=[]\n",
    "L_dict={}\n",
    "LL=[]\n",
    "label=-1\n",
    "for gesture in gesture_list:\n",
    "    for subject in subject_list:\n",
    "        for position in position_list:\n",
    "            new_path=path+'gesture_'+gesture+'/finger_1/subject_'+subject+'/essai_'+position+'/'\n",
    "            f=open(new_path+'valid_skeleton.txt')\n",
    "            iter_f=iter(f)\n",
    "            L=[]\n",
    "            for line in iter_f:\n",
    "                l=line.split()\n",
    "                l=np.array([float(i) for i in l])\n",
    "                nl=np.array([0 for i in range(num_joints*3)],dtype='float')\n",
    "                wrist=l[0:3]\n",
    "                nl[0:3]=wrist\n",
    "                palm=l[3:6]\n",
    "                direction=handsize_normalization(wrist,palm,1)\n",
    "                nl[3:6]=np.array(nl[0:3])+direction\n",
    "                for i in range(5):\n",
    "                    direction=handsize_normalization(l[3:6],l[(base_index[i]-1)*3:3*base_index[i]],1)\n",
    "                    nl[(base_index[i]-1)*3:3*base_index[i]]=nl[3:6]+direction\n",
    "                    direction=handsize_normalization(l[(base_index[i]-1)*3:3*base_index[i]],l[(first_index[i]-1)*3:3*first_index[i]],0.5)\n",
    "                    nl[(first_index[i]-1)*3:3*first_index[i]]=nl[(base_index[i]-1)*3:3*base_index[i]]+direction\n",
    "                    direction=handsize_normalization(l[(first_index[i]-1)*3:3*first_index[i]],l[(second_index[i]-1)*3:3*second_index[i]],0.5)\n",
    "                    nl[(second_index[i]-1)*3:3*second_index[i]]=nl[(first_index[i]-1)*3:3*first_index[i]]+direction\n",
    "                    direction=handsize_normalization(l[(second_index[i]-1)*3:3*second_index[i]],l[(tip_index[i]-1)*3:3*tip_index[i]],0.5)\n",
    "                    nl[(tip_index[i]-1)*3:3*tip_index[i]]=nl[(second_index[i]-1)*3:3*second_index[i]]+direction\n",
    "                #A=np.vstack((nl[0:3],nl[3:6],nl[6:9]))\n",
    "                #R,t=rigid_transform_3D(A)\n",
    "                #nl=transfer(R,t,nl)\n",
    "                nnl=[]\n",
    "                for ii in range(5):\n",
    "                    t=tup['tup'+str(ii+1)]\n",
    "                    buff=nl[3:6]\n",
    "                    for iii in range(4):\n",
    "                        ind=t[iii]\n",
    "                        nnl.append(nl[(ind-1)*3:3*ind]-buff)\n",
    "                        buff=nl[(ind-1)*3:3*ind]\n",
    "                buff=base_index[0]\n",
    "                for jj in range(4):\n",
    "                    ind=base_index[jj+1]\n",
    "                    nnl.append(nl[(ind-1)*3:3*ind]-buff)\n",
    "                    buff=nl[(ind-1)*3:3*ind]\n",
    "                buff=first_index[0]\n",
    "                for jj in range(4):\n",
    "                    ind=first_index[jj+1]\n",
    "                    nnl.append(nl[(ind-1)*3:3*ind]-buff)\n",
    "                    buff=nl[(ind-1)*3:3*ind]\n",
    "                buff=second_index[0]\n",
    "                for jj in range(4):\n",
    "                    ind=second_index[jj+1]\n",
    "                    nnl.append(nl[(ind-1)*3:3*ind]-buff)\n",
    "                    buff=nl[(ind-1)*3:3*ind]\n",
    "                buff=tip_index[0]\n",
    "                for jj in range(4):\n",
    "                    ind=tip_index[jj+1]\n",
    "                    nnl.append(nl[(ind-1)*3:3*ind]-buff)\n",
    "                    buff=nl[(ind-1)*3:3*ind]\n",
    "                nnnl=nnl\n",
    "                nnl=np.array(nnl).reshape(9,12)\n",
    "                nnl=nnl.tolist()\n",
    "                L.extend(nnl)\n",
    "            L_dict[gesture+subject+position]=np.array(L)\n",
    "            LL.extend(L)\n",
    "K = 128\n",
    "gmm = GMM(n_components=K, covariance_type='diag')\n",
    "gmm.fit(np.array(LL))\n",
    "for gesture in gesture_list:\n",
    "    label=label+1\n",
    "    for subject in subject_list:\n",
    "        for position in position_list:\n",
    "            fv = fisher_vector(L_dict[gesture+subject+position], gmm)\n",
    "            X.append(fv.tolist())\n",
    "            Y.append(label)\n",
    "            \n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct rate is 0.5\n",
      "correct rate is 0.5416666666666666\n",
      "correct rate is 0.5583333333333333\n",
      "correct rate is 0.6\n",
      "correct rate is 0.5416666666666666\n",
      "correct rate is 0.55\n",
      "correct rate is 0.525\n",
      "correct rate is 0.5583333333333333\n",
      "correct rate is 0.5333333333333333\n",
      "correct rate is 0.5416666666666666\n",
      "correct rate is 0.5333333333333333\n",
      "0.543939393939394\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "c=[]\n",
    "k=range(0,len(X))\n",
    "for itr in range(11):\n",
    "    train_index=random.sample(k,round(0.6*len(X)))\n",
    "    train_set=set(train_index)\n",
    "    test_set=set(k)-train_set\n",
    "    test_index=list(test_set)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    cor=0\n",
    "    for i in train_index:\n",
    "        X_train.append(X[i])\n",
    "        Y_train.append(Y[i])\n",
    "    for j in test_index:\n",
    "        X_test.append(X[j])\n",
    "        Y_test.append(Y[j])\n",
    "    from sklearn import svm\n",
    "    lin_clf=svm.LinearSVC()\n",
    "    lin_clf.fit(X_train, Y_train) \n",
    "    for i in range(len(X_test)):\n",
    "        predict=lin_clf.predict([X_test[i]])\n",
    "        if predict[0]==Y_test[i]:\n",
    "            cor=cor+1\n",
    "    print('correct rate is'+' '+str(cor/len(X_test)))\n",
    "    c.append(cor/len(X_test))\n",
    "print(np.mean(c))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct rate is 0.5666666666666667\n",
      "correct rate is 0.6\n",
      "correct rate is 0.55\n",
      "correct rate is 0.7166666666666667\n",
      "correct rate is 0.5833333333333334\n",
      "correct rate is 0.5\n",
      "correct rate is 0.6333333333333333\n",
      "correct rate is 0.6666666666666666\n",
      "correct rate is 0.55\n",
      "correct rate is 0.4666666666666667\n",
      "correct rate is 0.5666666666666667\n",
      "0.5818181818181818\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "c=[]\n",
    "k=range(0,len(X))\n",
    "for itr in range(11):\n",
    "    train_index=random.sample(k,round(0.8*len(X)))\n",
    "    train_set=set(train_index)\n",
    "    test_set=set(k)-train_set\n",
    "    test_index=list(test_set)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    cor=0\n",
    "    for i in train_index:\n",
    "        X_train.append(X[i])\n",
    "        Y_train.append(Y[i])\n",
    "    for j in test_index:\n",
    "        X_test.append(X[j])\n",
    "        Y_test.append(Y[j])\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    for i in range(len(X_test)):\n",
    "        predict=clf.predict([X_test[i]])\n",
    "        if predict[0]==Y_test[i]:\n",
    "            cor=cor+1\n",
    "    print('correct rate is'+' '+str(cor/len(X_test)))\n",
    "    c.append(cor/len(X_test))\n",
    "print(np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "1.058914425845294\n",
      "0.5000000000000002\n",
      "0.5000000000000002\n",
      "1.2615052414578256\n",
      "0.4999999999999999\n",
      "0.5000000000000004\n",
      "0.4999999999999995\n",
      "1.54090336577105\n",
      "0.5000000000000003\n",
      "0.5000000000000001\n",
      "0.5000000000000002\n",
      "1.709708645575143\n",
      "0.5\n",
      "0.5\n",
      "0.5000000000000001\n",
      "1.8536029761436865\n",
      "0.5000000000000001\n",
      "0.5\n",
      "0.5000000000000008\n",
      "4.775031605249675\n",
      "0.4386171410597597\n",
      "0.31633891830123967\n",
      "0.3472614145246845\n",
      "6.261266944311889\n",
      "0.5840524315312596\n",
      "0.410589840908716\n",
      "0.5417112764530155\n",
      "7.740166448194982\n",
      "0.7485985820154973\n",
      "0.511018452574967\n",
      "0.7355064781113841\n",
      "9.218662497168898\n",
      "0.9160830444876733\n",
      "0.6137851006884427\n",
      "0.9613125161504406\n"
     ]
    }
   ],
   "source": [
    "f=open('/Users/lay/Desktop/DHG2016/gesture_1/finger_1/subject_1/essai_1/new_feature_2.txt')\n",
    "iter_f=iter(f)\n",
    "f=0\n",
    "for line in iter_f:\n",
    "    l=line.split()\n",
    "    l=np.array([float(i) for i in l])\n",
    "    for i in (range(len(l)//3)):\n",
    "        ll=l[i*3:3*(i+1)]\n",
    "        print(np.linalg.norm(ll))\n",
    "    if f==0:\n",
    "        break\n",
    "    f=f+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "K = 64\n",
    "N = 1000\n",
    "xx, _ = make_classification(n_samples=N)\n",
    "xx_tr, xx_te = xx[: -100], xx[-100: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
