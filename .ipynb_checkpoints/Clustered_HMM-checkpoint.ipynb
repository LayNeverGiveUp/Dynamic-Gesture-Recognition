{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dtw import dtw\n",
    "from numpy import linalg as la\n",
    "from numpy.linalg import norm\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "import pdb\n",
    "from hmmlearn import hmm\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "path='/Users/lay/Desktop/DHG2016/'\n",
    "import shutil \n",
    "np.set_printoptions(threshold=np.inf)  \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using all subjects and all positions\n",
    "gesture_list=['1','3','4','5','6']\n",
    "subject_list=[str(i) for i in range(1,21)]\n",
    "position_list=[str(i) for i in range(1,6)]\n",
    "single_finger_list=['2','4','5','6']\n",
    "state_list=[3,3,3,3,3]\n",
    "num_train=19\n",
    "testgesture_list=['1','3','4','5','6']\n",
    "feature_file='feature_1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate data structure that gestures all grouped in the form of dictionary with gesture+subject+essai as indexes\n",
    "#the data has two dictionaries, one for list and the other for numpy\n",
    "gesture_dict={}\n",
    "distance_gesture_dict={}\n",
    "for gesture in gesture_list:\n",
    "    feature=[]\n",
    "    length=[]\n",
    "    for subject in subject_list:\n",
    "        for position in position_list:\n",
    "            if gesture in single_finger_list:\n",
    "                finger='1'\n",
    "            else:\n",
    "                finger='2'\n",
    "            new_path=path+'gesture_'+gesture+'/finger_'+finger+'/subject_'+subject+'/essai_'+position+'/'\n",
    "            f=open(new_path+feature_file)\n",
    "            iter_f=iter(f)\n",
    "            L=[]\n",
    "            for line in iter_f:\n",
    "                l=line.split()\n",
    "                l=[float(i) for i in l]\n",
    "                L.append(l)\n",
    "            gesture_dict[subject+'_'+gesture+'_'+position]=L    \n",
    "            distance_gesture_dict[subject+'_'+gesture+'_'+position]=np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter1 correct rate is 1.0\n",
      "iter2 correct rate is 0.68\n",
      "iter3 correct rate is 0.84\n",
      "iter4 correct rate is 0.88\n",
      "iter5 correct rate is 0.76\n",
      "iter6 correct rate is 0.92\n",
      "iter7 correct rate is 0.64\n",
      "iter8 correct rate is 0.92\n",
      "iter9 correct rate is 0.92\n",
      "iter10 correct rate is 0.96\n",
      "iter11 correct rate is 0.88\n",
      "iter12 correct rate is 0.8\n",
      "iter13 correct rate is 0.6\n",
      "iter14 correct rate is 0.92\n",
      "iter15 correct rate is 0.84\n",
      "iter16 correct rate is 0.76\n",
      "iter17 correct rate is 0.6\n",
      "iter18 correct rate is 0.92\n",
      "iter19 correct rate is 0.88\n",
      "iter20 correct rate is 0.56\n",
      " correct rate is 0.8140000000000001\n"
     ]
    }
   ],
   "source": [
    "max_d=23\n",
    "k_list=[3,3,3,3,3]\n",
    "k_try=[3,3,4,4,3]\n",
    "path='/Users/lay/Desktop/DHG2016/'\n",
    "c=[]\n",
    "ytrue=[]\n",
    "ypred=[]\n",
    "for ite in range(1,21):\n",
    "    #clear buffer every time\n",
    "    shutil.rmtree('/Users/lay/Desktop/Jupyter code/buffer') \n",
    "    os.mkdir('/Users/lay/Desktop/Jupyter code/buffer')\n",
    "    #decide the subjects for training and testing\n",
    "    #Hyperparameter here is the num_train\n",
    "    testsubject_list=[str(ite)]\n",
    "    trainsubject_list=set(subject_list)-set(testsubject_list)\n",
    "    trainsubject_list=list(trainsubject_list)\n",
    "    trl=[int(i) for i in trainsubject_list]\n",
    "    trl.sort()\n",
    "    subject_train=trl\n",
    "    trainsubject_list=[str(i) for i in trl]\n",
    "    #for gesture count\n",
    "    fg=0 \n",
    "    #for model count\n",
    "    fm=0 \n",
    "    num_hmm=[]\n",
    "    train_dict={}\n",
    "    train_len_dict={}\n",
    "    for gesture in gesture_list:\n",
    "        fg=fg+1\n",
    "        dis=pickle.load(open('/Users/lay/Desktop/Jupyter code/nn_distance'+str(fg)+'.txt', 'rb'))\n",
    "        \n",
    "        #get partial distance matrix according to subject list\n",
    "        index=[]\n",
    "        dis=np.array(dis)\n",
    "        for i in subject_train:\n",
    "            index.extend(range((i-1)*5,5*i))\n",
    "        new_dis=dis[:,index]\n",
    "        new_dis=new_dis[index,:]\n",
    "        dis=new_dis.tolist()\n",
    "        '''\n",
    "        #hierarchy clustering \n",
    "        #reshape the distance to a vector\n",
    "        D=[]\n",
    "        for i in range(len(dis)):\n",
    "            for j in range(i+1,len(dis)):\n",
    "                D.append(dis[i][j])\n",
    "        D=np.asarray(D)\n",
    "        \n",
    "        k=k_list[fg-1]\n",
    "        from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "        Z = linkage(D, 'ward')\n",
    "        clustering_index=fcluster(Z,max_d,criterion='distance')\n",
    "        ty=np.unique(clustering_index).shape\n",
    "        clustering_index.tolist()\n",
    "        '''\n",
    "        #k-means clustering\n",
    "        for i in range(len(dis)):\n",
    "            for j in range(len(dis[0])):\n",
    "                if dis[i][j]!=0:\n",
    "                    dis[i][j]=1/dis[i][j]\n",
    "                if dis[i][j]==0:\n",
    "                    dis[i][j]=1\n",
    "        for i in range(len(dis)):\n",
    "            ss=sum(dis[i])\n",
    "            for j in range(len(dis[0])):\n",
    "                dis[i][j]=dis[i][j]/ss\n",
    "        from numpy import linalg as LA\n",
    "        w, v = LA.eig(np.array(dis))\n",
    "        from sklearn.cluster import KMeans\n",
    "        k=k_try[fg-1]\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0).fit(v)\n",
    "        clustering_index=kmeans.labels_\n",
    "        ty=np.unique(clustering_index).shape\n",
    "        clustering_index.tolist()\n",
    "        for i in range(len(clustering_index)):\n",
    "            clustering_index[i]=clustering_index[i]+1\n",
    "    \n",
    "     \n",
    "            \n",
    "            \n",
    "        for i in range(1,ty[0]+1):\n",
    "            ind=[j for j in range(len(clustering_index)) if clustering_index[j]==i]\n",
    "            train=[]\n",
    "            train_len=[]\n",
    "            for ii in range(len(ind)):\n",
    "                n_subject=ind[ii]//5\n",
    "                position=str(ind[ii]%5+1)\n",
    "                subject=str(subject_train[n_subject])\n",
    "                train.extend(gesture_dict[subject+'_'+gesture+'_'+position])\n",
    "                x=len(gesture_dict[subject+'_'+gesture+'_'+position])\n",
    "                train_len.append(x)\n",
    "            train_dict[gesture+str(i)]=train\n",
    "            train_len_dict[gesture+str(i)]=train_len\n",
    "        num_hmm.append(i)\n",
    "        from hmmlearn import hmm\n",
    "        for j in range(num_hmm[fg-1]):\n",
    "            fm=fm+1\n",
    "            X=np.array(train_dict[gesture+str(j+1)])\n",
    "            le=train_len_dict[gesture+str(j+1)]\n",
    "            remodel=hmm.GMMHMM(n_components=state_list[fg-1],n_iter=100,covariance_type=\"diag\",init_params=\"cm\", params=\"cmt\")\n",
    "            remodel.startprob_ = np.array([1.0, 0.0, 0.0])\n",
    "            remodel.transmat_ = np.array([[0.5, 0.5, 0.0],\n",
    "                                [0.0, 0.5, 0.5],\n",
    "                                 [0.0, 0.0, 1.0]])\n",
    "            remodel.fit(X,le)\n",
    "            joblib.dump(remodel,'/Users/lay/Desktop/Jupyter code/buffer/clustered_hmm'+str(fm)+'.pkl')\n",
    "    \n",
    "    #test part\n",
    "    num=0\n",
    "    correct=0\n",
    "    for gesture in testgesture_list:\n",
    "        iiid=[]\n",
    "        for subject in testsubject_list:\n",
    "            for position in position_list:\n",
    "                if gesture in single_finger_list:\n",
    "                    finger='1'\n",
    "                else:\n",
    "                    finger='2'\n",
    "                num=num+1\n",
    "                new_path=path+'gesture_'+gesture+'/finger_'+finger+'/subject_'+subject+'/essai_'+position+'/'\n",
    "                f=open(new_path+feature_file)\n",
    "                iter_f=iter(f)\n",
    "                L=[]\n",
    "                for line in iter_f:\n",
    "                    l=line.split()\n",
    "                    l=[float(i) for i in l]\n",
    "                    L.append(l)\n",
    "                Y=np.array(L)\n",
    "                pre=[]\n",
    "                for j in range(sum(num_hmm)):\n",
    "                    hmm=joblib.load('/Users/lay/Desktop/Jupyter code/buffer/clustered_hmm'+str(j+1)+'.pkl')\n",
    "                    pre.append(hmm.score(Y))   \n",
    "                n_hmm=pre.index((max(pre)))\n",
    "                if n_hmm<num_hmm[0]:\n",
    "                    iid=0\n",
    "                elif num_hmm[0]-1<n_hmm<num_hmm[0]+num_hmm[1]:\n",
    "                    iid=1\n",
    "                elif num_hmm[0]+num_hmm[1]-1<n_hmm<num_hmm[0]+num_hmm[1]+num_hmm[2]:\n",
    "                    iid=2\n",
    "                elif num_hmm[0]+num_hmm[1]+num_hmm[2]-1<n_hmm<num_hmm[0]+num_hmm[1]+num_hmm[2]+num_hmm[3]:\n",
    "                    iid=3\n",
    "                else:\n",
    "                    iid=4\n",
    "                iiid.append(n_hmm)\n",
    "                ypred.append(iid)\n",
    "                ytrue.append(gesture_list.index(gesture))\n",
    "                if iid==gesture_list.index(gesture):\n",
    "                    correct=correct+1\n",
    "                #print ('true:'+str(gesture_list.index(gesture)))\n",
    "                #print ('predict:'+str(iid))\n",
    "    print('iter'+str(ite)+' correct rate is '+str(correct/num))\n",
    "    c.append(correct/num)\n",
    "print(' correct rate is '+str(np.mean(c)))\n",
    "confusion_matrix=confusion_matrix(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance matrix for each gesture for all subjects (Has Been Calculated)\n",
    "fff=0\n",
    "for gesture in gesture_list:\n",
    "    fff=fff+1\n",
    "    dis=[]\n",
    "    for subject1 in subject_list:\n",
    "        for position1 in position_list:\n",
    "            x1=distance_gesture_dict[subject1+'_'+gesture+'_'+position1]\n",
    "            dis1=[]\n",
    "            for subject2 in subject_list:\n",
    "                for position2 in position_list:\n",
    "                    x2=distance_gesture_dict[subject2+'_'+gesture+'_'+position2]\n",
    "                    dist, cost, acc_cost, path=dtw(x1,x2,dist=lambda x, y: norm(x - y, ord=1))\n",
    "                    dis1.append(dist)\n",
    "            dis.append(dis1)\n",
    "            #store distance matrix of each gesture \n",
    "            import pickle\n",
    "            pickle.dump(dis,open('/Users/lay/Desktop/Jupyter code/nn_distance'+str(fff)+'.txt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute distance matrix for each gesture with fastDTW\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "fff=0\n",
    "for gesture in gesture_list:\n",
    "    fff=fff+1\n",
    "    dis=[]\n",
    "    for subject1 in subject_list:\n",
    "        for position1 in position_list:\n",
    "            x1=distance_gesture_dict[subject1+'_'+gesture+'_'+position1]\n",
    "            dis1=[]\n",
    "            for subject2 in subject_list:\n",
    "                for position2 in position_list:\n",
    "                    x2=distance_gesture_dict[subject2+'_'+gesture+'_'+position2]\n",
    "                    distance, path = fastdtw(x1, x2, dist=euclidean)\n",
    "                    dis1.append(distance)\n",
    "            dis.append(dis1)\n",
    "            #store distance matrix of each gesture \n",
    "            import pickle\n",
    "            pickle.dump(dis,open('/Users/lay/Desktop/Jupyter code/n_distance'+str(fff)+'.txt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fancy_dendrogram(*args, **kwargs):\n",
    "\tmax_d = kwargs.pop('max_d', None)\n",
    "\tif max_d and 'color_threshold' not in kwargs:\n",
    "\t\tkwargs['color_threshold'] = max_d\n",
    "\tannotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "\tddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "\tif not kwargs.get('no_plot', False):\n",
    "\t\tplt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "\t\tplt.xlabel('sample index or (cluster size)')\n",
    "\t\tplt.ylabel('distance')\n",
    "\t\tfor i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "\t\t\tx = 0.5 * sum(i[1:3])\n",
    "\t\t\ty = d[1]\n",
    "\t\t\tif y > annotate_above:\n",
    "\t\t\t\tplt.plot(x, y, 'o', c=c)\n",
    "\t\t\t\tplt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5), textcoords='offset points', va='top', ha='center')\n",
    "\t\tif max_d:\n",
    "\t\t\tplt.axhline(y=max_d, c='k')\n",
    "\treturn ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization part\n",
    "fg=1\n",
    "dis=pickle.load(open('/Users/lay/Desktop/Jupyter code/distance'+str(fg)+'.txt', 'rb'))  \n",
    "subject_train=range(1,21)\n",
    "#get partial distance matrix according to subject list\n",
    "index=[]\n",
    "dis=np.array(dis)\n",
    "for i in subject_train:\n",
    "    index.extend(range((i-1)*5,5*i))\n",
    "new_dis=dis[:,index]\n",
    "new_dis=new_dis[index,:]\n",
    "dis=new_dis.tolist()\n",
    "\n",
    "#hierarchy clustering \n",
    "#reshape the distance to a vector\n",
    "D=[]\n",
    "for i in range(len(dis)):\n",
    "    for j in range(i+1,len(dis)):\n",
    "        D.append(dis[i][j])\n",
    "D=np.asarray(D)\n",
    "\n",
    "#visualization\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from matplotlib import pyplot as plt\n",
    "Z = linkage(D, 'average')\n",
    "plt.figure(figsize=(25, 10))\n",
    "fancy_dendrogram(Z,truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=12., show_contracted=True, annotate_above=1)\n",
    "plt.show()\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "c, coph_dists = cophenet(Z, D)\n",
    "print(c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
